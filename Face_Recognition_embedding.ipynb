{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Face_Recognition_embedding.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"10qOymIYU68qYY38pIN9r1Dq7Z_iLlrz4","authorship_tag":"ABX9TyMwlEOhvogWu7aI0FwsYmpy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zMbvylvEXL6K"},"source":["## Face Recognition based on facial features"]},{"cell_type":"markdown","metadata":{"id":"ynqD0OZ4sBMA"},"source":["This program consists of three main phases\n","\n","\n","1. Detect the individual face in the image and extract facial features using pre-trained models\n","2. Store people's information in the dataset, including the name, image and feature extracted from their face in the image\n","3. Compare the extracted features\n","\n","> 1. Compare the similarity of each person's face with another person in the dataset\n","> 2. Compare the faces in the new image with the faces of the people in the dataset and get their similarities\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bGWO8d-1wT8X"},"source":["# 1. **Face Detection** :\n","    \n","   Model : Multi-Task Cascaded Convolutional Neural Network (MTCNN)"]},{"cell_type":"code","metadata":{"id":"ZhopG2RQYL8n"},"source":["!pip install Pillow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XWvHIhhcXFf1"},"source":["!pip install mtcnn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UX6B5J4zRfs_","executionInfo":{"status":"ok","timestamp":1631034666839,"user_tz":-270,"elapsed":3222,"user":{"displayName":"houriye esfahanian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5_pK5gPYEz--AvpLYBJnE326wzubojw522_-V=s64","userId":"02267185748560927344"}}},"source":["from os import listdir\n","from os.path import isdir\n","from PIL import Image\n","from numpy import asarray\n","from mtcnn.mtcnn import MTCNN\n","\n","# extract a single face from a given photograph\n","def extract_face(filename, required_size=(160, 160)):\n","\t# load image from file\n","\timage = Image.open(filename)\n","\t# convert to RGB, if needed\n","\timage = image.convert('RGB')\n","\t# convert to array\n","\tpixels = asarray(image)\n","\t# create the detector, using default weights\n","\tdetector = MTCNN()\n","\t# detect faces in the image\n","\tresults = detector.detect_faces(pixels)\n","\t# extract the bounding box from the first face\n","\tx1, y1, width, height = results[0]['box']\n","\tx1, y1 = abs(x1), abs(y1)\n","\tx2, y2 = x1 + width, y1 + height\n","\t# extract the face\n","\tface = pixels[y1:y2, x1:x2]\n","\t# resize pixels to the model size\n","\timage = Image.fromarray(face)\n","\timage = image.resize(required_size)\n","\tface_array = asarray(image)\n","\treturn face_array\n","\n","# load images and extract faces for all images in a directory\n","def load_faces(directory):\n","\tfaces = list()\n","\t# enumerate files\n","\tfor filename in listdir(directory):\n","\t\t# path\n","\t\tpath = directory + filename\n","\t\t# get face\n","\t\tface = extract_face(path)\n","\t\t# store\n","\t\tfaces.append(face)\n","\treturn faces\n","\n","# load a dataset that contains one subdir for each class that in turn contains images\n","def load_dataset(directory):\n","\tX, y = list(), list()\n","\t# enumerate folders, on per class\n","\tfor subdir in listdir(directory):\n","\t\t# path\n","\t\tpath = directory + subdir + '/'\n","\t\t# skip any files that might be in the dir\n","\t\tif not isdir(path):\n","\t\t\tcontinue\n","\t\t# load all faces in the subdirectory\n","\t\tfaces = load_faces(path)\n","\t\t# create labels\n","\t\tlabels = [subdir for _ in range(len(faces))]\n","\t\t# summarize progress\n","\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n","\t\t# store\n","\t\tX.extend(faces)\n","\t\ty.extend(labels)\n","\treturn asarray(X), asarray(y)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"SACK8VjVX-Ur"},"source":["from numpy import savez_compressed\n","\n","# load dataset\n","X, y = load_dataset('/content/drive/MyDrive/Git_Repos/FaceRecognition_FaceNet_repo/faces-dataset/data/')\n","print(X.shape, y.shape)\n","# save arrays to one file in compressed format\n","savez_compressed('/content/drive/MyDrive/Git_Repos/FaceRecognition_FaceNet_repo/dataset.npz', X, y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OOnm4Yrauu4z"},"source":["X, y = load_dataset('/content/drive/MyDrive/Git_Repos/FaceRecognition_FaceNet_repo/faces-dataset/data/')\n","print(X.shape, y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zydreXVT31Gs"},"source":["# 2. Extract face embedding using FaceNet\n","FaceNet is a face recognition system developed in 2015 by researchers at Google that achieved then state-of-the-art results on a range of face recognition benchmark datasets.\n","\n","The FaceNet model can be used to extract high-quality features from faces, called face embeddings. \n","\n","Face embedding actually is a vector with length 128 consist of numeric data."]},{"cell_type":"code","metadata":{"id":"-9YJ1xtPR_Wv"},"source":["from keras.models import load_model\n","\n","# load the facenet model\n","model = load_model('/content/drive/MyDrive/Git_Repos/FaceRecognition_FaceNet_repo/facenet_keras.h5')\n","print('Loaded Model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H2f8xNUvRwr8","executionInfo":{"status":"ok","timestamp":1631034740355,"user_tz":-270,"elapsed":372,"user":{"displayName":"houriye esfahanian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg5_pK5gPYEz--AvpLYBJnE326wzubojw522_-V=s64","userId":"02267185748560927344"}}},"source":["from numpy import expand_dims\n","\n","# calculate a face embedding for each face in the dataset using facenet\n","# get the face embedding for one face\n","def get_embedding(model, face_pixels):\n","\t# scale pixel values\n","\tface_pixels = face_pixels.astype('float32')\n","\t# standardize pixel values across channels (global)\n","\tmean, std = face_pixels.mean(), face_pixels.std()\n","\tface_pixels = (face_pixels - mean) / std\n","\t# transform face into one sample\n","\tsamples = expand_dims(face_pixels, axis=0)\n","\t# make prediction to get embedding\n","\tyhat = model.predict(samples)\n","\treturn yhat[0]"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zhsXqHXkWFsT"},"source":["Note:\n","\n","If you see lots of warning after running the following cell.\n","These warnings are related to the implementation of tensorflow in the Google colab and there is no specific problem.\n","\n","The warnings will not hurt performance."]},{"cell_type":"code","metadata":{"id":"EnllPbI7ggSH"},"source":["from numpy import load\n","from numpy import asarray\n","from numpy import savez_compressed\n","\n","# load the face dataset\n","data = load('/content/drive/MyDrive/Git_Repos/FaceRecognition_FaceNet_repo/dataset.npz')\n","X, y = data['arr_0'], data['arr_1']\n","print('Loaded: ', X.shape, y.shape)\n","# convert each face in the  dataset to an embedding\n","newX = list()\n","for face_pixels in X:\n","\tembedding = get_embedding(model, face_pixels)\n","\tnewX.append(embedding)\n","newX = asarray(newX)\n","print(newX.shape)\n","# save arrays to one file in compressed format\n","savez_compressed('/content/drive/MyDrive/Git_Repos/FaceRecognition_FaceNet_repo/embeddings.npz', newX, y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MAdPU09R_-63"},"source":["# 3. Comparing facial features with using cosine_similarity metric"]},{"cell_type":"code","metadata":{"id":"bGKa0PHl-Y_l"},"source":["#@title compare face features with new image and recoginize person with our dataset(.npz) (without using database) { form-width: \"1px\" }\n","from scipy.spatial import distance\n","import numpy as np\n","\n","#from sklearn.metrics.pairwise import cosine_similarity\n","newImage = \"/content/drive/MyDrive/Git_Repos/FaceRecognition_FaceNet_repo/faces-dataset/test/leonardo_dicaprio_640.jpg\"\n","face = extract_face(newImage)\n","embedding = get_embedding(model, face)\n","\n","# load the face dataset\n","data = load('/content/drive/MyDrive/Git_Repos/FaceRecognition_FaceNet_repo/embeddings.npz')\n","X, y = data['arr_0'], data['arr_1']\n","#print('Loaded: ', X.shape, y.shape)\n","\n","# compare face with each faces in data set\n","result = list()\n","for embedings in X:\n","    cosine_similarity = 1 - distance.cosine(embedings, embedding)\n","\t#cosine_similarity = cosine_similarity(embedings, embedding, dense_output=True)\n","    result.append(cosine_similarity)\n","print(type(result))\n","print(result)\n","\n","#out put of recognizing\n","if max(result) > 0.88 :\n","    num_person = result.index(max(result))\n","    print(y[num_person])\n","else:\n","    print(\"this person is not recoginized\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1vSR24P5jMHk"},"source":["# **End**"]}]}